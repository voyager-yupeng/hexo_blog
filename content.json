{"posts":[{"title":"DeepLearningAndrewNg","text":"The Deep Learning Specialization is a foundational program that will help you understand the capabilities, challenges, and consequences of deep learning and prepare you to participate in the development of leading-edge AI technology. 1.4 æ­£åˆ™åŒ– 1.5 å·ç§¯æ­¥é•¿ è¾“å‡ºçš„å›¾ç‰‡çš„size [[DeepLearningAndrewNg-Figure-1.png|00]] [[DeepLearningAndrewNg-Figure-2.png]] å¦‚æœä¸æ˜¯æ•´æ•° ï¼Œå‘ä¸‹å–æ•´ [[DeepLearningAndrewNg-Figure-4.png]] è“è‰²æ¡†åœ¨å¤–é¢çš„æ—¶å€™å°±ä¸è®¡ç®—å·ç§¯äº† 1.6 ä¸‰çº¬å·ç§¯ image-20200222162127021 æŒ‰ç…§æƒ¯ä¾‹ï¼Œè¿™ä¸¤ä¸ªncè¦ç›¸ç­‰ã€‚ 1.7 å•å±‚å·ç§¯ç½‘ç»œ ä»a[0]-&gt;a[1] [[DeepLearningAndrewNg-Figure-6.png]] ç¥ç»ç½‘ç»œæ‹Ÿåˆ å‚æ•°æ•°é‡è®¡ç®— [[DeepLearningAndrewNg-Figure-7.png]] éœ€è¦æ³¨æ„ï¼Œè¿™é‡Œæ¯ä¸ªå·ç§¯æ ¸ä¼šå¸¦æ¥28ä¸ªå‚æ•°ï¼ˆ27ä¸ªå·ç§¯æ ¸å†…çš„å‚æ•°ï¼Œ1ä¸ªbiasï¼‰ ä¸ç®¡å›¾ç‰‡è¾“å…¥å¤šå¤§ï¼Œå‚æ•°å§‹ç»ˆéƒ½æ˜¯280ä¸ªã€‚ï¼ˆä½ å·²ç»çŸ¥é“å¦‚ä½•æå–10ä¸ªç‰¹å¾ï¼Œå¯ä»¥åº”ç”¨åˆ°æ›´å¤§çš„å›¾ç‰‡ä¸­ï¼Œè€Œå‚æ•°æ•°é‡å´ä¸å˜ï¼‰ å„ç§æ ‡è®°çš„æ€»ç»“ [[DeepLearningAndrewNg-Figure-8.png]] [[DeepLearningAndrewNg-Figure-9.png]] ä¸Šæ ‡ç”¨æ¥è¡¨ç¤ºç¬¬å‡ å±‚ question [[DeepLearningAndrewNg-Figure-10.png]] è¿™é‡Œbiasçš„ç»´æ•°ä¸ºä»€ä¹ˆæ˜¯è¿™æ · 1.8 ç®€å•å·ç§¯ç½‘ç»œç¤ºä¾‹ [[DeepLearningAndrewNg-Figure-11.png]] å…¶ä¸­æœ€åä¸€å±‚æ˜¯å¹³æ»‘è¾“å‡ºä¸ºä¸€ä¸ªå‘é‡ï¼Œlogisticsæˆ–è€…æ˜¯softmaxï¼Œå–å†³äºæ˜¯æƒ³è¯†åˆ«ä¸€ä¸ªç‰©ä½“è¿˜æ˜¯ä¸åŒç±»åˆ«çš„ç‰©ä½“ã€‚ ç‰¹å¾å›¾çš„é«˜åº¦å’Œå®½åº¦åœ¨å‡å°ï¼Œé€šé“æ•°åœ¨å¢åŠ  å…³äºè¿™äº›æ‰€æœ‰å‚æ•°å¦‚ä½•ç¡®å®šï¼Œåé¢ä¼šè®² ä¸‰ç§ç§ç±»çš„å±‚ [[DeepLearningAndrewNg-Figure-12.png]] è™½ç„¶åªä½¿ç”¨Convå±‚ä¹Ÿå¯èƒ½æ„å»ºå‡ºå¾ˆå¥½çš„ç¥ç»ç½‘ç»œï¼Œä½†æ˜¯å¤§éƒ¨åˆ†ç¥ç»ç½‘ç»œæ¶æ„å¸ˆä¾ç„¶ä¼šæ·»åŠ poolå’ŒFC 1.9 pool poolä½œç”¨ ç¼©å‡æ¨¡å‹çš„å¤§å° æé«˜è®¡ç®—é€Ÿåº¦ æé«˜æ‰€æå–ç‰¹å¾çš„é²æ£’æ€§ poolingä¸¾ä¾‹&amp;ä¸ºä»€ä¹ˆè¦pooling maxpoolingçš„ç›´è§‚ç†è§£ â€‹ å‘ç°è¿™ä¸ªç‰¹å¾ï¼Œé‚£å°±å°†ä»–æœ€å¤§åŒ–ï¼›è¦æ˜¯æ²¡å‘ç°ï¼Œé‚£å°±è®¤ä¸ºæ²¡æœ‰ Average poolingæœ‰æ—¶å€™ä¼šç”¨ question æµ‹è¯•ä¸€ä¸‹maxpollingæ˜¯ä¸æ˜¯æŠŠå›¾åƒæ¨¡ç³Šäº† [[DeepLearningAndrewNg-Figure-13.png]] é€‰å‡ºæœ€å¤§çš„æ•°ï¼Œè¿™ä¸ªåœ¨æºç é‡Œæ˜¯æ€ä¹ˆæ‰§è¡Œçš„ï¼Ÿåœ¨ç¡¬ä»¶ä¸Šæœ‰æ²¡æœ‰åŠ é€Ÿçš„å¯èƒ½ï¼Ÿ 1.10 å·ç§¯ç¥ç»ç½‘ç»œä¸¾ä¾‹ï¼ˆæ•°å­—è¯†åˆ«ï¼‰ 1.11 ä¸ºä»€ä¹ˆä½¿ç”¨å·ç§¯ å…¨è¿æ¥è®©å‚æ•°å¤ªå¤šäº† [[DeepLearningAndrewNg-Figure-14.png]] æƒå€¼å…±äº« image-20200220174602468 ä¸ºä»€ä¹ˆå·ç§¯è®©å‚æ•°å˜å°‘äº†ï¼Œå› ä¸ºæƒå€¼å…±äº«ã€‚ å‡è®¾ä¸€ä¸ªå·ç§¯æ ¸å¯ä»¥æ£€æµ‹ç«–ç›´è¾¹ç¼˜ï¼Œé‚£ä¹ˆå®ƒå°±é€‚ç”¨äºä»»ä½•åœ°æ–¹ã€‚ ç¨€ç–è¿æ¥ å·¦è¾¹çº¢è‰²çš„æ¡†ï¼Œå†³å®šäº†å³è¾¹çº¢è‰²åœˆé‡Œçš„æ•°å­—30-&gt;å·¦è¾¹çº¢è‰²çš„æ¡†åªä¸å³è¾¹åœˆé‡Œçš„30è¿æ¥ â¬†ï¸å…¨è¿æ¥å’Œæƒå€¼å…±äº«è®©å‚æ•°å˜å°‘ æ€»ç»“ï¼Œä¸ºä»€ä¹ˆä½¿ç”¨å·ç§¯ é€šè¿‡æƒå€¼å…±äº«ã€ç¨€ç–è¿æ¥ï¼Œè®©å‚æ•°å˜å°‘ï¼ˆæ¯”å…¨è¿æ¥å°‘ï¼‰ å½“å›¾ç‰‡é‡Œçš„ç‰©ä½“å‘ç”Ÿå°çš„ç§»åŠ¨çš„æ—¶å€™ï¼Œä¹Ÿå¯ä»¥è®©ç»“æœåœ¨ä¸€å®šèŒƒå›´å†…ä¸å˜ 2.1 Mini-Batch 2.2 ç»å…¸ç½‘ç»œ LeNet-5 image-20200220190413959 é’ˆå¯¹é˜…è¯»è¿™ç¯‡ç»å…¸è®ºæ–‡çš„åŒå­¦ image-20200222155745573 è¿‡å»äººä»¬ç»å¸¸ç”¨Sigmoidå‡½æ•°å’ŒTanhå‡½æ•°ï¼Œä½†ç°åœ¨äººä»¬ä½ ç»å¸¸ç”¨Reluå‡½æ•° é€šè¿‡æŸç§å¤æ‚çš„è®¡ç®—æ–¹æ³•ï¼Œè®©ä¿¡é“æ•°éƒ½ä¿æŒä¸€è‡´ï¼Œä¸ºäº†å‡å°‘è¿ç®—é‡ã€‚ä½†ç°åœ¨è®¡ç®—éƒ½æ¯”è¾ƒå¿«é€Ÿäº†ï¼Œæ‰€ä»¥ä¸éœ€è¦è¿™æ ·äº†ã€‚ ç»å…¸çš„LeNet-5ç½‘ç»œåœ¨æ± åŒ–åè¿›è¡Œäº†éçº¿æ€§å‡½æ•°å¤„ç†ï¼ŒSigmoidã€‚è‡³äºä¸ºä»€ä¹ˆï¼Œä¹‹åä¼šè®²ã€‚ å»ºè®®ç²¾è¯»ç¬¬äºŒæ®µï¼Œç•¥è¯»ç¬¬ä¸‰æ®µ ç¬¬ä¸‰æ®µä»‹ç»äº†graph transformer networkï¼Œä½†å¦‚ä»Šæ²¡æœ‰å¹¿æ³›ä½¿ç”¨ã€‚ AlexNet åŸæ–‡æ˜¯224*224ï¼Œä½†å®é™…ä¸Š227*227ä¼šæ›´å¥½ è¡¨ç°æ›´å¥½çš„åŸå› ï¼š LeNet-5å‚æ•°åªæœ‰60thousandï¼ŒALexNetæœ‰60millionä¸ªå‚æ•° ä½¿ç”¨äº†ReLuæ¿€æ´»å‡½æ•° é’ˆå¯¹é˜…è¯»è¿™ç¯‡ç»å…¸è®ºæ–‡çš„åŒå­¦ å½“æ—¶GPUè®¡ç®—è¾ƒæ…¢ï¼Œæ‰€ä»¥ä½¿ç”¨äº†å¤æ‚çš„æ–¹æ³•å»åœ¨ä¸¤ä¸ªGPUä¸Šå¹¶è¡Œ LRNï¼ˆlocal response normalizationï¼‰å±‚ï¼Œä½¿ç”¨çš„å¹¶ä¸å¹¿æ³›ã€‚å¤§è‡´æ€è·¯æ˜¯ï¼š é€‰å–ä¸€ä¸ªä½ç½®ï¼Œç©¿è¿‡æ•´ä¸ªä¿¡é“ï¼Œå°†æ‰€æœ‰å€¼å½’ä¸€åŒ–ã€‚ç†ç”±æ˜¯ä¹Ÿè®¸å¹¶ä¸éœ€è¦è¿™ä¹ˆå¤šçš„æ¿€æ´»ç¥ç»å…ƒï¼Œä½†åæ¥ç ”ç©¶è€…ä»¬å‘ç°ä¸æ€ä¹ˆèµ·ä½œç”¨ã€‚ VGG-16 è¿™ä¸ª16æ˜¯æŒ‡ è¿™æ˜¯ä¸ª1.38äº¿ï¼ˆ138millionï¼‰å‚æ•°çš„å·¨å‹ç½‘ç»œ ä½†æ˜¯å¸å¼•äººçš„æ˜¯ï¼Œç»“æ„å¹¶ä¸å¤æ‚ï¼Œç»“æ„å¾ˆè§„æ•´ã€‚éƒ½æ˜¯å‡ ä¸ªå·ç§¯è·Ÿç€å‡ ä¸ªæ± åŒ–ï¼ˆå¯ä»¥å‹ç¼©å›¾åƒå¤§å°ï¼‰ã€‚ ç¼ºç‚¹æ˜¯éœ€è¦è®­ç»ƒçš„ç‰¹å¾æ•°é‡éå¸¸å¤§ã€‚ ä½†æ˜¯å·ç§¯æ ¸çš„æ•°é‡å˜åŒ–æ˜¯æœ‰è§„å¾‹çš„ï¼Œç¿»å€ï¼ˆç»¿è‰²ç¬”è®°åœˆå‡ºæ¥äº†â¬‡ï¸ï¼‰ã€‚ [[DeepLearningAndrewNg-Figure-21.png]] ä½œè€…å½“æ—¶å¯èƒ½è®¤ä¸º512å·²ç»å¤Ÿå¤§äº†ï¼Œæ‰€ä»¥å¹¶æ²¡æœ‰è¿›è¡Œç»§ç»­ç¿»å€ è¿™ç§è®©å·ç§¯æ ¸ç¿»å€çš„æ“ä½œæ˜¯è¿™ç§ç½‘ç»œç»“æ„çš„æ€æƒ³ã€‚ è¿™ç¯‡æ–‡ç« ä»‹ç»äº†VGG-19ï¼Œä½†æ˜¯å’Œ16çš„æ•ˆæœå·®ä¸å¤šã€‚ æ–‡ä¸­æ­ç¤ºäº†ï¼Œéšç€ç½‘ç»œçš„å¢åŠ ï¼Œä¿¡é“æ•°çš„ç¿»å€å’Œå›¾ç‰‡çš„ç¼©å°ä¹‹é—´æ˜¯æœ‰è§„å¾‹çš„ï¼Œè¿™ä¸€ç‚¹æ¯”è¾ƒå¸å¼•äººã€‚ 2.3 æ®‹å·®ç½‘ç»œ å› ä¸ºæ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸çš„åŸå› ï¼Œæ‰€ä»¥è®­ç»ƒå¾ˆæ·±çš„ç½‘ç»œæ˜¯å¾ˆéš¾çš„ã€‚ä½†æ˜¯è¿™èŠ‚è¯¾è¦å­¦çš„skip connectionï¼ˆæˆ–è€…è¯´æ˜¯short cutï¼‰ï¼Œå¯ä»¥ä»æŸä¸€ç½‘ç»œå±‚ç›´æ¥è·å¾—æ¿€æ´»å€¼ï¼Œè·³è¿‡å¾ˆå¤šå±‚ç½‘ç»œï¼Œè¿™æ ·å¯ä»¥æ„å»ºåƒResNetä¸€æ ·çš„æ·±å±‚ç½‘ç»œã€‚ Residual block æ®‹å·®å— ä¿¡æ¯æµçš„ä¸»è·¯çº¿ [[DeepLearningAndrewNg-Figure-23.png]] â¬†ï¸å°†ä¿¡æ¯ç›´æ¥é€åˆ°äº†l+2å±‚ï¼Œä¸”åœ¨éçº¿æ€§ReLuæ¿€æ´»å‡½æ•°ä¹‹å‰ image-20200222164215334 â¬†ï¸plain networkï¼Œé€šè¿‡æ¯ä¸¤å±‚ä¹‹é—´åŠ ä¸Šè¿æ¥ï¼Œæ„æˆä¸€ä¸ªä¸€ä¸ªçš„æ®‹å·®å—ï¼Œä»è€Œå½¢æˆæ®‹å·®ç½‘ç»œã€‚ [[DeepLearningAndrewNg-Figure-25.png]] â¬†ï¸æ®‹å·®å—è®©â€œè¶Šæ·±è¶Šç²¾ç¡®â€æˆä¸ºäº†ç°å®ã€‚ 2.4 æ®‹å·®ç½‘ç»œä¸ºä»€ä¹ˆæœ‰æ•ˆ æ²¡å¤ªå¬æ‡‚ã€‚ã€‚ã€‚ é—®é¢˜ ä»€ä¹ˆæ˜¯hold-outäº¤å‰éªŒè¯ 2.5 1x1çš„å·ç§¯æœ‰ä»€ä¹ˆç”¨ æå‡ºæ–‡ç«  è™½ç„¶å…¶ä¸­å…³äºç½‘ç»œæ¶æ„çš„éƒ¨åˆ†æ²¡æœ‰å¾—åˆ°å¹¿æ³›çš„åº”ç”¨ï¼Œä½†æ˜¯è¿™ç§network in networkçš„ç†å¿µå´å¾ˆæœ‰å½±å“åŠ›ï¼Œå¾ˆå¤šå…¶ä»–ç½‘ç»œéƒ½å—ä»–å½±å“ï¼ŒåŒ…æ‹¬ä¸‹èŠ‚è¯¾è¦è®²çš„inceptionç½‘ç»œ åœ¨ä¸€ç»´ä¸Šçš„1x1å·ç§¯ç¡®å®æ²¡ä»€ä¹ˆç”¨ï¼Œä½†æ˜¯å¦‚æœæ˜¯å¤šä¸ªchannelçš„è¯ï¼Œå°±ä¼šæœ‰ç”¨ã€‚ [[DeepLearningAndrewNg-Figure-27.png]] 1x1å·ç§¯å®é™…ä¸Šåœ¨åšçš„æ˜¯ éå†ä¸€ä¸ªä½ç½®çš„32ä¸ªä¿¡é“ï¼ˆä¸€ä¸ªä½ç½®çš„åˆ‡ç‰‡ï¼‰ï¼Œå’Œå·ç§¯æ ¸ç›¸ä¹˜ï¼Œå¾—åˆ°ä¸€ä¸ªå®æ•°ï¼Œç„¶åReLuã€‚ å¯ä»¥è¿™æ ·ç†è§£â¬‡ï¸ ç›¸å½“äºæ˜¯ä¸€ç§å…¨è¿æ¥ï¼Œä¸€ä¸ªåˆ‡ç‰‡ä¸­çš„32ä¸ªå…ƒç´ ï¼Œå’Œï¼Œè¾“å‡ºå±‚ä¸­ä¸€ä¸ªåˆ‡ç‰‡ä¸­çš„number of filtersä¸ªå…ƒç´  [[DeepLearningAndrewNg-Figure-28.jpg]] 1x1å·ç§¯çš„ä¸€ä¸ªä¾‹å­ é€šé“å¤ªå¤šï¼Œé€šè¿‡ä½¿ç”¨å¤šä¸ª1x1å·ç§¯æ ¸æ¥è®©é€šé“æ•°å‡å°‘ã€‚ [[DeepLearningAndrewNg-Figure-29.png]] é—®é¢˜ ä½¿ç”¨1x1å·ç§¯æ ¸å‹ç¼©é€šé“æ•°ï¼Œè¿™æ ·çœŸçš„å¯ä»¥å—ï¼Ÿè¿™å¹¶æ²¡æœ‰æ€ä¹ˆä¿ç•™åŸæ¥çš„ä¿¡æ¯ï¼Œè€Œæ˜¯ç›´æ¥ä¸€è‚¡è„‘åŠ èµ·æ¥äº†ã€‚ èƒ½ä¸èƒ½é€‰æ‹©æ›´æœ‰ç”¨çš„ä¿¡æ¯ç•™ä¸‹æ¥ å‰ªææ˜¯å‰ªæ‰äº†å·ç§¯æ ¸ï¼Œè¿˜æ˜¯å‰ªæ‰äº†æŸä¸€å±‚çš„è¾“å‡ºï¼Ÿ 2.6 è°·æ­Œinceptionç½‘ç»œç®€ä»‹ inceptinoç½‘ç»œå¯ä»¥æ›¿ä½ å†³å®šç”¨ä»€ä¹ˆè§„æ ¼çš„å·ç§¯æ ¸ã€åŠ ä¸åŠ poolingå±‚ æå‡ºæ–‡ç« ï¼› æ ¸å¿ƒæ€è·¯ [[DeepLearningAndrewNg-Figure-31.png]] æŠŠä¸åŒè§„æ ¼çš„å·ç§¯æ ¸ã€poolingï¼Œè¾“å‡ºçš„ä¸œè¥¿éƒ½å †å åœ¨ä¸€èµ·ï¼Œç„¶åè®©ç½‘ç»œè‡ªå·±å»å­¦ä¹ åˆ°åº•è¦ä¸è¦è¿›è¡Œè¿™äº›æ“ä½œã€‚ è®¡ç®—ä»£ä»·â€”â€”ç›´æ¥è®¡ç®— è®¡ç®—ä»£ä»·â€”â€”å…ˆä½¿ç”¨1*1convå¯¹ç½‘ç»œè¿›è¡Œå‹ç¼© [[DeepLearningAndrewNg-Figure-32.png]] å…ˆå‹ç¼©ç½‘ç»œï¼Œç„¶åå†æ‰©å¤§ã€‚ä¹˜æ³•è¿ç®—æ¬¡æ•°é™åˆ°äº†120millionã€‚ å› ä¸ºåŠ æ³•æ¬¡æ•°å’Œä¹˜æ³•æ¬¡æ•°åŸºæœ¬ç›¸åŒï¼Œæ‰€ä»¥è¿™é‡Œåªè®¡ç®—äº†ä¹˜æ³•æ¬¡æ•°ã€‚ æ€»ç»“ å¦‚æœä½ ä¸æƒ³è‡ªå·±å†³å®šé€‰ç”¨ä»€ä¹ˆè§„æ ¼çš„å·ç§¯æ ¸ï¼Œé‚£å°±ç”¨inceptionã€‚ æ¶‰åŠåˆ°è®¡ç®—æˆæœ¬çš„æ—¶å€™ï¼Œå¯ä»¥ç”¨1x1å·ç§¯æ¥åˆ¶é€ ç“¶é¢ˆå±‚ï¼ˆå…ˆå‹ç¼©ç½‘ç»œï¼Œç„¶åå†æ‰©å¤§ï¼‰ï¼Œæ¥é™ä½è®¡ç®—æˆæœ¬ã€‚ä½†æ˜¯è¿™ç§å‹ç¼©ä¼šä¸ä¼šè®©ç¥ç»ç½‘ç»œçš„æ€§èƒ½ä¸‹é™å‘¢ï¼Ÿäº‹å®è¯æ˜ï¼Œåˆç†çš„ä½¿ç”¨çš„è¯ï¼Œå¯ä»¥è®©æ•ˆæœå…¼å¾—ã€‚ 2.11 å‘é‡åŒ– ç”¨çŸ©é˜µä¹˜æ³•ä»£æ›¿äºŒç»´å¾ªç¯ [[DeepLearningAndrewNg-Figure-33.png]] [[DeepLearningAndrewNg-Figure-34.png]] 2.13 å‘é‡åŒ–Logisticå›å½’ å¤šæ ·æœ¬è¾“å…¥ï¼ˆçºµå‘å åŠ xï¼‰ã€å•Logisticï¼ˆwä¸€ç»´ï¼‰ è¿™é‡Œçš„x(1)æ˜¯è¡¨ç¤ºä¸€ä¸ªæ ·æœ¬ï¼Œè€Œå‘é‡åŒ–åå°±æ˜¯æŠŠæ¯ä¸ªæ ·æœ¬çš„ç‰¹å¾å‘é‡ï¼ˆåˆ—å‘é‡ï¼‰verticallyå èµ·æ¥ï¼Œwhile å‚æ•°wTè¿˜æ˜¯ä¸€è¡Œï¼Œæ­¤æ—¶è¾“å‡ºçš„aä¹Ÿä¼šverticallyå èµ·æ¥ã€‚è¿™æ · å°±ç›¸å½“äºä¸€æ¬¡çŸ©é˜µè¿ç®—å®Œæˆäº†å¤šä¸ªæ ·æœ¬çš„forwardï¼Œå¯ä»¥ä¸€æ¬¡åœ¨å¾ˆå¤šæ•°æ®é›†ä¸Šè¿›è¡Œæ¢¯åº¦ä¸‹é™ã€‚ [[DeepLearningAndrewNg-Figure-35.png]] attention æ³¨æ„åŠ›ï¼šåœ¨è¾“å‡ºç¿»è¯‘å¥å­çš„ç¬¬ä¸€ä¸ªè¯çš„æ—¶å€™ï¼Œè¦çœ‹sourceå¥çš„å“ªäº›éƒ¨åˆ†ï¼ˆä¸æ˜¯ç¬¬ä¸€ä¸ªå•è¯ï¼Œä½†ä¹Ÿè‚¯å®šä¸æ˜¯å¥å°¾ï¼Œä¸èƒ½çœ‹å¾—å¤ªè¿œäº†ï¼‰ï¼Œè¦åˆ†åˆ«å¯¹sourceå¥ä¸­çš„æ¯ä¸ªéƒ¨åˆ†æœ‰å¤šå°‘æ³¨æ„åŠ›ã€‚ 3.2 ç¥ç»ç½‘ç»œè¡¨ç¤ºå’Œè¾“å‡ºï¼ˆå•æ ·æœ¬è¾“å…¥ã€å¤šLogisticï¼‰ hiden layerï¼šå› ä¸ºåœ¨è®­ç»ƒçš„è¿‡ç¨‹ä¸­ï¼Œè¿™äº›èŠ‚ç‚¹çš„å€¼å¹¶ä¸çŸ¥é“ã€‚ ä¸€èˆ¬åœ¨è¯´å‡ å±‚ç¥ç»ç½‘ç»œçš„æ—¶å€™ä¸ç®—è¾“å…¥å±‚ï¼ˆ0å±‚ï¼‰ï¼Œä½†æ˜¯ç®—æœ€åçš„classfierå±‚ï¼ˆå³ä½¿æ˜¯1ä¸ªèŠ‚ç‚¹ï¼‰ã€‚ è¿™é‡Œçš„x1ï¼Œx2ï¼Œx3å…±åŒç»„æˆäº†ä¸€ä¸ªxçš„ç‰¹å¾å‘é‡è¾“å…¥ï¼ˆx1ï¼Œx2ï¼Œx3åˆ†åˆ«ä»£è¡¨ä¸€ä¸ªæ•°ï¼‰ã€‚ wæ˜¯(4,3)ï¼Œ4ä»£è¡¨è¿™å±‚æœ‰å‡ ä¸ªç¥ç»å…ƒèŠ‚ç‚¹ï¼Œ3ä»£è¡¨å‰ä¸€å±‚çš„è¾“å…¥æ˜¯å‡ ç»´çš„ã€‚ [[DeepLearningAndrewNg-Figure-36.png]] å•æ ·æœ¬è¾“å…¥ï¼ˆxä¸€åˆ—ï¼‰ã€å¤šLogisticï¼ˆwå¤šç»´ï¼‰ [[DeepLearningAndrewNg-Figure-37.png]] è¿™é‡ŒæŠŠè¡Œå‘é‡wTçºµå‘å †å ï¼Œè€Œè¾“å…¥å°±æ˜¯ä¸€ä¸ªæ ·æœ¬çš„åˆ—å‘é‡ï¼Œæ‰€ä»¥ä¹˜å‡ºæ¥çš„zä¹Ÿæ˜¯çºµå‘æ’åˆ—ã€‚ç„¶åå¯¹Zç”¨ä¸€ä¸‹sigmodï¼Œå°±ç”Ÿæˆäº†çºµå‘æ’åˆ—çš„a[1]ã€‚ [[DeepLearningAndrewNg-Figure-38.png]] ç»´æ•°æ•´ç† [[DeepLearningAndrewNg-Figure-39.png]] 3.4 å¤šä¸ªæ ·æœ¬çš„å‘é‡åŒ–ï¼ˆå¤šæ ·æœ¬è¾“å…¥ã€å¤šLogisticï¼‰ æ™®é€šè®­ç»ƒæ–¹æ³•ï¼šä¸€ä¸ªä¸€ä¸ªè®¡ç®—y_predictï¼Œå¦‚æœè¦è®¡ç®—æ‰€æœ‰mä¸ªæ ·æœ¬çš„predictï¼Œé‚£ä¹ˆéœ€è¦åšä¸€ä¸ªfor i=1 to mçš„å¾ªç¯ã€‚ç°ç”¨å‘é‡åŒ–æ¥ä¸€æ¬¡è®¡ç®—æ‰€æœ‰æ ·æœ¬çš„predictã€‚ [[DeepLearningAndrewNg-Figure-40.png]] å¤šæ ·æœ¬è¾“å…¥ã€å¤šLogistic å¤šæ ·æœ¬ï¼šæŠŠåˆ—å‘é‡æ¨ªç€æ’èµ·æ¥ã€‚å¤šLogisticï¼ˆç¥ç»ç½‘ç»œï¼‰ï¼šæŠŠwTè¡Œå‘é‡ç«–ç€æ’èµ·æ¥ã€‚ å…³æ³¨ç´«è‰²éƒ¨åˆ†ï¼š æ¨ªå‘æ‰«ï¼Œä¼šæ‰«è¿‡ä¸åŒçš„è®­ç»ƒæ ·æœ¬ï¼ˆtraining examplesï¼‰ã€‚ çºµå‘æ‰«ï¼Œä¼šæ‰«è¿‡éšè—å±‚ä¸åŒèŠ‚ç‚¹çš„å€¼aï¼ˆhiden unitsï¼‰ã€‚ [[DeepLearningAndrewNg-Figure-41.png]] å¤šæ ·æœ¬å‘é‡åŒ–è¾“å…¥çš„è¯¦ç»†è§£é‡Šâ¬‡ï¸ã€‚ [[DeepLearningAndrewNg-Figure-42.png]] 3.6 æ¿€æ´»å‡½æ•° æœ€æ™®é€šçš„æ˜¯sigmodï¼Œä½†tanhå‡½æ•°ï¼ˆå®é™…ä¸Šæ˜¯å‘ä¸‹å¹³ç§»åçš„sigmodï¼‰å¤§éƒ¨åˆ†æ—¶å€™è¡¨ç°æ›´å¥½ã€‚ åœ¨äºŒåˆ†ç±»çš„æœ€åä¸€ä¸ªå•èŠ‚ç‚¹å±‚çš„æ—¶å€™ï¼Œå¯ä»¥ç”¨sigmodè¾“å‡º0-1çš„å€¼ã€‚ ä½†sigmodå’Œtanhéƒ½åœ¨ä¸¤ç«¯æœ‰æ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜ï¼Œæ‰€ä»¥Reluï¼ˆä¿®æ­£çº¿æ€§å•å…ƒï¼‰ç”¨çš„æ›´å¤šã€‚Reluåœ¨è´Ÿæ•°æ—¶å¯¼æ•°ä¸ºè´Ÿï¼Œå°½ç®¡å®è·µä¸­æ²¡ä»€ä¹ˆé—®é¢˜ï¼Œä½†ä¹Ÿæœ‰ä¸€ç§æ”¹è¿›ç‰ˆæœ¬çš„Relu called Leaky Reluï¼ˆå¸¦æ³„éœ²çš„Reluï¼‰ï¼Œä½†ç”¨çš„ä¸å¦‚Reluå¤šã€‚ Reluå’ŒLeaky Reluä¼šè®©å­¦ä¹ é€Ÿåº¦æ›´å¿«ï¼Œå› ä¸ºåœ¨å¤§éƒ¨åˆ†Zç©ºé—´ï¼Œå¯¼æ•°æ¯”è¾ƒå¤§ã€‚ [[DeepLearningAndrewNg-Figure-43.png]] å››ç§å¸¸ç”¨çš„æ¿€æ´»å‡½æ•° [[DeepLearningAndrewNg-Figure-44.png]] 3.7 ä¸ºä»€ä¹ˆè¦ç”¨éçº¿æ€§çš„æ¿€æ´»å‡½æ•° å¦‚æœé‡‡ç”¨çº¿æ€§çš„æ¿€æ´»å‡½æ•°ï¼Œé‚£ä¹ˆæœ€åè¾“å‡ºçš„ä¸œè¥¿å°±æ˜¯è¾“å…¥çš„çº¿æ€§ç»„åˆï¼Œé‚£ä¹ˆç¥ç»ç½‘ç»œhiden layerå±‚æ•°å†å¤šä¹Ÿä¸ä¼šå¢åŠ black boxçš„å¤æ‚åº¦ï¼Œè¿˜ä¸å¦‚éƒ½å»æ‰ã€‚ [[DeepLearningAndrewNg-Figure-45.png]] Reluä¸ºä»€ä¹ˆä¸æ˜¯çº¿æ€§çš„ï¼Œæ€ä¹ˆç†è§£ï¼Ÿ [[DeepLearningAndrewNg-Figure-46.png]] [[DeepLearningAndrewNg-Figure-47.png]] 5.2 åºåˆ—æ¨¡å‹æ•°å­¦ç¬¦å· [[DeepLearningAndrewNg-Figure-48.png]] one-hotè¯å‘é‡è¡¨ç¤ºæ³• [[DeepLearningAndrewNg-Figure-49.png]] 5.3 å¾ªç¯ç¥ç»ç½‘ç»œ ä¸ºä»€ä¹ˆä¸ç”¨standard network inputå’Œoutputå¯èƒ½ä¼šæœ‰ä¸åŒçš„é•¿åº¦ã€‚ ä¸èƒ½å…±äº«åœ¨textä¸åŒä½ç½®å­¦ä¹ åˆ°çš„featureã€‚ [[DeepLearningAndrewNg-Figure-50.png]] è¿™æ ·RNNæœ‰ä¸€ä¸ªç¼ºç‚¹ï¼šè¿™æ ·çš„ç»“æ„åªèƒ½åˆ©ç”¨åˆ°å½“å‰time stepä¹‹å‰çš„ä¿¡æ¯ï¼Œæ²¡æ³•åˆ©ç”¨åˆ°ä¹‹åçš„ä¿¡æ¯ã€‚æ¯”å¦‚ä¸‹é¢çš„ä¾‹å­ä¸­ï¼Œåªçœ‹åˆ°Teddyå’Œå®ƒä¹‹å‰çš„å•è¯ï¼Œæ˜¯æ— æ³•å‡†ç¡®åˆ¤æ–­è¯­ä¹‰çš„ã€‚ä¹‹åä¼šæåˆ°BRNNï¼ˆåŒå‘å¾ªç¯ç¥ç»ç½‘ç»œï¼‰ [[DeepLearningAndrewNg-Figure-51.png]] RNN forwardè¿‡ç¨‹çš„æ•°å­¦è¿ç®— Waxè¡¨ç¤ºåé¢è¦ä¹˜ä¸€ä¸ªxç±»å‹çš„å˜é‡ï¼Œå¹¶ä¸”è®¡ç®—å¾—å‡ºçš„æ˜¯ä¸€ä¸ªaç±»å‹çš„å˜é‡ã€‚ g1å’Œg2å¯ä»¥æ˜¯ä¸åŒçš„æ¿€æ´»å‡½æ•°ã€‚åœ¨è¿™é‡Œç”±äºæ˜¯name entityé—®é¢˜ï¼Œæ˜¯ä¸€ä¸ªäºŒåˆ†ç±»é—®é¢˜ï¼Œæ‰€ä»¥g2å¯ä»¥ç”¨sigmoidå‡½æ•°ã€‚ [[DeepLearningAndrewNg-Figure-52.png]] ç®€åŒ–RNNçš„æ•°å­¦è¡¨ç¤º Waaå’ŒWaxæ¨ªå‘å †å ï¼Œa&lt;t-1&gt;å’Œx&lt;t&gt;çºµå‘å †å ï¼Œç„¶åå°±å¯ä»¥ç®€åŒ–æˆä¸‹å›¾å³ä¸Šè§’çš„è¡¨ç¤ºæ–¹å¼ã€‚ [[DeepLearningAndrewNg-Figure-53.png]] 5.4 é€šè¿‡æ—¶é—´çš„åå‘ä¼ æ’­ å•ä¸ªtime stepä¸Šçš„loss functionã€æ•´ä¸ªåºåˆ—çš„loss functionï¼ˆæŠŠæ‰€æœ‰å•æ­¥lossåŠ èµ·æ¥ï¼‰ã€‚ åœ¨è¿™é‡Œï¼Œåå‘ä¼ æ’­åŒç†ï¼Œåœ¨è®¡ç®—å›¾ä¸Šæ‰€æœ‰forwardè®¡ç®—æ—¶çš„ç®­å¤´éƒ½åè¿‡æ¥è®¡ç®—ä¸€æ¬¡ã€‚ å…¶ä¸­æœ€é‡è¦çš„ä¼ é€’å°±æ˜¯æ²¿ç€time stepè¿›è¡Œçš„åå‘ä¼ æ’­ã€‚æ‰€ä»¥ä¹Ÿå«backpropagation through timeã€‚ [[DeepLearningAndrewNg-Figure-54.png]] 5.5 å…¶ä»–RNN Tx ï¼= Ty çš„æƒ…å†µï¼Œå¯ä»¥é€šè¿‡ä¿®æ”¹ä¸Šè¿°RNNï¼Œè¾¾åˆ°è¿™ç§æ•ˆæœã€‚ [[DeepLearningAndrewNg-Figure-55.png]] å¤šå¯¹ä¸€ç»“æ„ã€‚ ä¸€èˆ¬ç”¨åœ¨æ–‡æœ¬æƒ…ç»ªåˆ†ç±»ã€‚ [[DeepLearningAndrewNg-Figure-56.png]] ä¸€å¯¹å¤šç»“æ„ã€‚çº¢è‰²çš„ç»“æ„ï¼šå¹³æ—¶åœ¨åšçš„æ—¶å€™å…¶å®ä¹Ÿä¼šæŠŠæ¯ä¸€æ­¥ç”Ÿæˆçš„ç»“æœfeedè¿›ä¸‹ä¸€å±‚ã€‚ ä¸€èˆ¬ç”¨åœ¨æ–‡æœ¬/éŸ³ä¹ç”Ÿæˆã€‚ [[DeepLearningAndrewNg-Figure-57.png]] å˜é•¿å¤šå¯¹å¤šç»“æ„ ä¸ºäº†åº”å¯¹è¾“å…¥å’Œè¾“å‡ºé•¿åº¦ä¸åŒçš„æƒ…å†µï¼Œå…ˆç”¨encoderå¤„ç†è¾“å…¥ï¼Œå†ç”¨decoderå¤„ç†è¾“å‡ºã€‚ [[DeepLearningAndrewNg-Figure-58.png]] æ€»ç»“ one to oneï¼šå°±æ˜¯æ™®é€šçš„ç½‘ç»œ one to manyï¼šsequence generationï¼Œä¾‹å¦‚æ–‡æœ¬/éŸ³ä¹ç”Ÿæˆ many to oneï¼šæ–‡æœ¬æƒ…æ„Ÿåˆ†ç±» many to manyï¼šname entity many to many(å˜é•¿)ï¼šæ–‡æœ¬ç¿»è¯‘ [[DeepLearningAndrewNg-Figure-59.png]] 5.6 è¯­è¨€æ¨¡å‹å’Œåºåˆ—ç”Ÿæˆ å¦‚æœä½ æƒ³è¦ä½ çš„æ¨¡å‹èƒ½å¤Ÿè¯†åˆ«å¥å­æœ«å°¾çš„è¯ï¼Œé‚£ä¹ˆå¯ä»¥åœ¨æ¯ä¸ªå¥å­åé¢åŠ ä¸€ä¸ªEOSï¼ˆä¹Ÿç”¨one-hotè¡¨ç¤ºæ³•è¡¨ç¤ºï¼Œå³ EOSä¹Ÿåœ¨è¯å…¸é‡Œï¼‰ï¼Œç„¶åå»è®­ç»ƒã€‚æ ‡ç‚¹ç¬¦å·åŒç†ã€‚ [[DeepLearningAndrewNg-Figure-60.png]] ç¬¬ä¸€æ­¥a&lt;1&gt;çš„æ—¶å€™ï¼Œa&lt;0&gt;å’Œx&lt;1&gt;çš„è¾“å…¥éƒ½æ˜¯é›¶å‘é‡ï¼Œæ‰€ä»¥è¾“å‡ºy&lt;1&gt;ç›¸å½“äºæ˜¯åœ¨é¢„æµ‹æ˜¯ä»»ä½•ä¸€ä¸ªè¯çš„æ¦‚ç‡æ˜¯å¤šå°‘ã€‚ y&lt;1&gt;ç›¸å½“äºæ˜¯åœ¨é¢„æµ‹åœ¨æ²¡æœ‰æ¡ä»¶çš„æƒ…å†µä¸‹ï¼Œæ˜¯ä¸€ä¸ªå•è¯çš„æ¦‚ç‡æ˜¯å¤šå°‘ã€‚ y&lt;2&gt;æ˜¯åœ¨é¢„æµ‹åœ¨å‰æ–‡æ˜¯Catsçš„æ¡ä»¶ä¸‹ï¼Œä¸‹ä¸€ä¸ªå•è¯æ˜¯averageçš„æ¦‚ç‡æ˜¯å¤šå°‘ã€‚ [[DeepLearningAndrewNg-Figure-61.png]] loss function [[DeepLearningAndrewNg-Figure-62.png]] Meta-learning å’Œlife-long learningçš„åŒºåˆ«ï¼Œlife-long Learingæ˜¯ä¸æ–­è®­ç»ƒåŒä¸€ä¸ªæ¨¡å‹ï¼Œä½¿å…¶æŒæ¡å¤šç§Taskï¼ŒMetaæ˜¯æŒ‡ä»ä¸åŒTaskä¸­å­¦ä¼šå­¦ä¹ çš„æ–¹æ³•ã€‚ ç„¶åsupport setå’Œquery setæ˜¯meta learningé‡Œçš„ä¸“æœ‰åè¯ï¼Œå°±æ˜¯æŒ‡æ¯ä¸ªå­ä»»åŠ¡é‡Œçš„training setå’Œtesting set [[DeepLearningAndrewNg-Figure-63.png]] ç¬¬ä¸€æ­¥ï¼šdefine a set of learning algorithm ç°è‰²boxé‡Œçš„ä¸œè¥¿å°±æ˜¯ä¸€ä¸ªlearning algorithmã€‚ image-20210322190746956 å¦‚ä½•è¯„ä»·ä¸€ä¸ªlearning algorithmçš„å¥½åï¼Œä¹Ÿå®šä¹‰ä¸€ä¸ªloss funcã€‚ image-20210322191302435 æ¯ä¸ªmeta Learingçš„æ•°æ®é›†exampleå°±æ˜¯ä¸€ä¸ªTaskã€‚ä¸ºä»€ä¹ˆè¦å’Œfew-shotä¸€èµ·æ¥è®²ï¼Œå› ä¸ºæ¯ä¸ªexampleæ˜¯ä¸€ä¸ªTaskï¼Œwhichéœ€è¦è¿›è¡Œè®­ç»ƒæ‰çŸ¥é“Lossæ˜¯å¤šå°‘ï¼Œå¦‚æœä¸æ˜¯few-shotçš„è¯ï¼Œé‚£è·‘ä¸€æ¬¡å°±éœ€è¦çš„æ—¶é—´å¤ªé•¿äº†ã€‚ é—®é¢˜ï¼Œè®­ç»ƒç”¨çš„Taskè¯´æ˜¯ä¸åŒä»»åŠ¡ï¼Œä½†å®é™…ä¸Šéƒ½æ˜¯åˆ†ç±»ä»»åŠ¡ï¼Œè¿™ä¹Ÿç®—ä¸åŒä»»åŠ¡å—ï¼Ÿ image-20210322191734335 æ€»ç»“ä¸€ä¸‹ï¼š image-20210322192350535 MAML image-20210322193651850 model pre-trainingå’Œmeta-learningçš„åŒºåˆ« MAMLæ˜¯å…³æ³¨trainä¹‹åçš„å‚æ•°ã€‚ image-20210322193504020 ### å‚è€ƒé“¾æ¥ 1. MAMLå’ŒReptileæ–¹æ³•çš„è§£é‡Šï¼Œå‚è€ƒäº†æå®æ¯…è€å¸ˆçš„ç½‘è¯¾ï¼Œ https://zhuanlan.zhihu.com/p/136975128 2. æœºå™¨äººè¿åŠ¨å­¦ bç«™è¯¾ç¨‹ï¼šå°å¤§æœºå™¨äººå­¦ä¹‹è¿åŠ¨å­¦â€”â€”æ—æ²›ç¾¤ ç§»åŠ¨ é™æ€åˆšä½“çŠ¶æ€æè¿° body frameæ˜¯åœ¨åˆšä½“ä¸­å¿ƒæ„å»ºçš„åæ ‡ç³»ã€‚ [[C:_vault\\0-Learn\\2-Course-20210402134114841.png]]\"image-20210402134114841\" style=\"zoom:50%;\" /&gt; åŠ¨æ€åˆšä½“çŠ¶æ€æè¿° ä¸­å¿ƒåæ ‡çš„æ‰€æœ‰ç‚¹æ„æˆäº†è½¨è¿¹ï¼Œå…¶ä»–å„ç§å¾®åˆ†æ„æˆäº†é€Ÿåº¦ç­‰ä¿¡æ¯ã€‚ [[DeepLearningAndrewNg-Figure-71.png]]\"image-20210402134914321\" style=\"zoom:50%;\" /&gt; å…·ä½“æ¥è¯´å°±æ˜¯å¦‚ä¸‹ï¼Œä»¥åˆšä½“ä¸­å¿ƒåœ¨ä¸–ç•Œåæ ‡ç³»é‡Œçš„åæ ‡ï¼ˆå‘é‡ï¼‰æ¥æè¿°ä½ç½®ã€‚ [[DeepLearningAndrewNg-Figure-72.png]]\"image-20210402135224988\" style=\"zoom:50%;\" /&gt; è½¬åŠ¨ã€æ—‹è½¬çŸ©é˜µ å·¦ä¸Šè§’ä»£è¡¨åŸºå‡†ï¼Œæ¯”å¦‚è¿™é‡Œçš„ABRå°±æ˜¯è¯´åˆšä½“Bä¸Šçš„body frameçš„å„è½´æ–¹å‘ï¼Œåœ¨{A}é‡Œè¡¨ç¤ºæ˜¯ä»€ä¹ˆçŸ©é˜µã€‚ è¿™é‡Œå†™å‡ºæ¥çš„å°±å«æ—‹è½¬çŸ©é˜µã€‚å«ä¹‰æ˜¯ï¼šBç›¸å¯¹äºAçš„çŠ¶æ€ï¼Œé‡Œé¢3ä¸ªcollumåˆ†åˆ«è¡¨ç¤º{B}çš„3ä¸ªè½´åœ¨{A}ä¸­çš„æ–¹å‘ã€‚ [[DeepLearningAndrewNg-Figure-73.png]]\"image-20210402141315803\" style=\"zoom:33%;\" /&gt; [[DeepLearningAndrewNg-Figure-74.png]]\"image-20210402141429766\" style=\"zoom:30%;\" /&gt; æ€»ç»“æ¥è¯´å°±æ˜¯ä¸‹é¢è¿™å¼ å›¾ã€‚direct cosineæ–¹å‘ä½™å¼¦ã€‚ [[DeepLearningAndrewNg-Figure-75.png]]\"image-20210402141837894\" style=\"zoom:50%;\" /&gt; ä¾‹é¢˜ï¼šæ±‚{B}ç›¸å¯¹äº{A}çš„å§¿æ€ï¼ˆæ—‹è½¬çŸ©é˜µï¼‰ã€‚ æŠŠBæ¯ä¸ªè½´åœ¨Aä¸‹çš„è¡¨ç¤ºå†™æˆåˆ—å‘é‡ï¼Œç„¶åæ¨ªå‘stackèµ·æ¥ã€‚ [[DeepLearningAndrewNg-Figure-76.png]]\"image-20210402143829169\" style=\"zoom:50%;\" /&gt; æ€§è´¨1ï¼š Aåˆ°Bçš„æ—‹è½¬çŸ©é˜µï¼Œå’ŒBåˆ°Açš„æ—‹è½¬çŸ©é˜µï¼Œæ˜¯äº’ä¸ºè½¬ç½®çš„å…³ç³»ã€‚ [[DeepLearningAndrewNg-Figure-77.png]]\"image-20210402144608794\" style=\"zoom:50%;\" /&gt; æ€§è´¨ 2ï¼š å› ä¸ºåæ ‡ç³»ä¸€èˆ¬éƒ½æ˜¯æ­£äº¤çš„ï¼Œæ‰€ä»¥ä¼šæœ‰ä¸€ä¸ªå¾ˆå¥½çš„æ€§è´¨ï¼Œé€†çŸ©é˜µ==è½¬ç½®çŸ©é˜µã€‚è¿™å¯ä»¥å¤§å¤§æ–¹ä¾¿æ—‹è½¬çŸ©é˜µç›¸å…³çš„è®¡ç®—ã€‚ [[DeepLearningAndrewNg-Figure-78.png]]\"image-20210402145623684\" style=\"zoom:30%;\" /&gt; [[DeepLearningAndrewNg-Figure-79.png]]\"image-20210402145347509\" style=\"zoom:30%;\" /&gt; æ—‹è½¬çŸ©é˜µçš„é™å®šæ¡ä»¶ å¯¹äº3DOFsçš„ç†è§£ï¼šæ—‹è½¬çŸ©é˜µæœ‰3x3å…±9ä¸ªå‚æ•°ï¼Œä½†æ˜¯å› ä¸ºæœ‰6ä¸ªé™å®šæ¡ä»¶ï¼ˆ3ä¸ªcolluméƒ½æ˜¯å•ä½å‘é‡ã€äº’ç›¸å‚ç›´ï¼‰ï¼Œæ‰€ä»¥å®é™…åªæœ‰3ä¸ªæ˜¯è‡ªç”±å˜é‡ï¼Œä»è€Œå¯¼è‡´åªæœ‰3ä¸ªè‡ªç”±åº¦ã€‚è¿™é‡Œä»æ•°å­¦ä¸Šçš„ç†è§£ï¼Œè·Ÿç‰©ç†ä¸Šçš„ç†è§£ï¼ˆä¸‰ä¸ªæ—‹è½¬æ–¹å‘ï¼‰ä¸€è‡´ã€‚ ä½†æ˜¯åŠ äº†å¦‚ä¸Šçš„çº¦æŸæ¡ä»¶åï¼Œæ€ä¹ˆä¿è¯è‡ªç”±å˜é‡å°±æ˜¯æ¯ä¸ªcollumä¸€ä¸ªå‘¢ï¼Ÿ","link":"/hexo_blog/2023/05/17/DeepLearningAndrewNg/"},{"title":"Machine Learning with Graphs","text":"This course focuses on the computational, algorithmic, and modeling challenges specific to the analysis of massive graphs. By means of studying the underlying graph structure and its features, students are introduced to machine learning techniques and data mining tools apt to reveal insights on a variety of networks. 1. Intro 1.2 Application ä¸åŒå°ºåº¦ï¼š - æ•´å›¾å°ºåº¦ï¼šæ•´ä¸ªå›¾çš„é¢„æµ‹å’Œç”Ÿæˆ - å­å›¾å°ºåº¦ - èŠ‚ç‚¹å°ºåº¦ - è¾¹å°ºåº¦ ç‚¹é¢„æµ‹ï¼šé¢„æµ‹æŸä¸€ä¸ªç‚¹çš„ç‰¹å¾ è¾¹é¢„æµ‹ï¼šé¢„æµ‹ä¸¤ç‚¹ä¹‹é—´æ˜¯å¦æœ‰è¿è¾¹ï¼ˆçŸ¥è¯†å›¾è°±ï¼‰ å›¾åˆ†ç±»ï¼šåˆ†å­å±æ€§é¢„æµ‹ å­å›¾æ£€æµ‹ï¼šæ£€æµ‹æ˜¯å¦æœ‰ç‚¹æ„æˆå­å›¾ï¼Œç¤¾åŒºå‘ç° å…¶ä»–ç±»å‹ï¼š å›¾ç”Ÿæˆï¼šæ¯”å¦‚ç”Ÿæˆå…·æœ‰ç‰¹å®šå±æ€§çš„æ–°åˆ†å­ç»“æ„ å›¾æ¼”åŒ–ï¼šæ¥æ¨¡æ‹Ÿç‰©ç†ç°è±¡ Example of Node-level ML Tasks é—®é¢˜ï¼šç»™å®šä¸€ä¸ªæ°¨åŸºé…¸åºåˆ—ï¼Œæ˜¯å¦å¯ä»¥é¢„æµ‹å…¶å¯èƒ½æ„æˆçš„è›‹ç™½è´¨ç©ºé—´ç»“æ„ï¼Ÿ é‡ç‚¹è¿›æ­¥æ˜¯ï¼ŒAlphaFoldæå‡ºäº†spatial graphï¼Œå¹¶æŠŠæ°¨åŸºé…¸è¡¨ç¤ºæˆäº†spatial graphã€‚ nodeï¼šæ°¨åŸºé…¸ edgeï¼šè¡¨ç¤ºæ°¨åŸºé…¸ä¹‹é—´çš„ç©ºé—´è·ç¦»å…³ç³» Examples of Edge-level ML Tasks We are basically doing link prediction or trying to understand the relationship between different nodes. Recommender Systems Using a bipartite graph creates a much more powerful embedding than just using images. Nodes: User and items Edges: User-item interactions Goal: predict future edges Drug Side Effects Prediction Task: Given a pair of drugs, predict adverse side effects. To deal with this, create a two-level heterogeneous network using known protein-protein interactions and drug-protein interactions to predict unknown drug-drug side effects. &gt;Inspiration for the Global Rigidity Recovery (GRR) Problem: &gt;We can also model the GRR Problem as an edge prediction task: predict a set of edges that, if we move some drones to establish them, the graph would be global rigidity; meanwhile, this process consumes the least power. ### Examples of Graph-level ML Tasks Drug Discovery Model this problem as a graph classification problem. Alternatively, we can also model it as a graph generation problem. Note that we can also optimize the existing graph to have desirable properties. &gt;Inspiration for the Global Rigidity Recovery Problem: &gt; Optimize the existing \"Broken Graph\" to have Global Rigidity properties. Simulation Learning Framework Ieteratily generation next frame position and update the current position. &gt;Inspiration for the Global Rigidity Recovery Problem): &gt;This work uses a time sequence model to predict the effect of gravity. Similarly, we can assume a virtual force keeps the graph converging to global rigidity and uses some analogous model to predict the effect of this force. 1.3 Choice of Graph Representation Undirected graph: use undirected links to represent symmetrical or reciprocal relations. Directed graph: use directed links to represent arcs relation. Bipartite Graph äºŒåˆ†å›¾ Figure-14 Folded/Projected Bipartite Graph Use one of the side nodes in a bipartite graph, and project it by some rules, such as they have at least one common neighbor. Helpful when it has two types of nodes: author and papers, movie and customers. weighted graphs ### more types of graphs Connectivity Different meanings of connectivity in undirected graph and directed graph. Figure-19 2. Feature Design 2.1 Node features There are some traditional node features. ### Node degree Node degree is a fundamental but essential feature of graph nodes. However, the drawback of using it to characterize the structure and position of a node is that it treats all the neighbors equally; for example, nodes with the same degree are distinguishable even though they may be in different parts of the network. Node Centrality Node degree counts the neighboring nodes without capturing their importance. So we introduce the Node centrality to overcome this drawback. Node centrality takes the node importance in a graph into account. Different types of Node centrality: - Engienvector centrality - Betweenness centrality - Closeness centrality - and many others... #### Eigenvector centrality Betweenness centrality The idea is that if a node is an important connector, then it has high importance. Closeness centrality The idea is that the more centered a node is, the shorter the path to everyone else is and the more important it is. Clustering Coefficient This measures the density of neighbors of a node. The numerator is how many edges exist in neighbors. The denominator is how many edges it could maximally have. Observation from the Clustering coefficient: The clustering coefficient actually counts the triangles in the ego network. Graphlets å¼‚æ„è¿é€šå­å›¾ Different node color means different structure features. #### Graphlet Degree Vector(GDV) Now define Graphlet Degree Vector(GDV) Take an example of how to calculate Graphlets. a-d represents different types of Graphlets, and different node colors represent different positions. GDV simply counts all the cases when node v respectively in each position of every possible Graphlets. So if we consider neighbors of 4 hops, we got a GDV of 73 elements. Conclusion: - GDV captures fine-grained topological properties of the local neighborhood around a node. - Useful for predicting the role of a particular node in the network. E.g., predicting protein function. &gt;Inspiration for the Global Rigidity Recovery Problem): &gt;- Embedding GDV features in node to represent local topology structure features. Summary of 2.1 Node features Summary of Importance-based Features Summary of Structure-based features: Captures the topological properties of the local neighborhood around the node. Useful for predicting the role of a particular node in the network. E.g., predicting protein function. ## 2.2 Edge features Edge features = Features for a pair of nodes Two pipelines of Link prediction task: - Links are missing at random: used mainly in a static network like protein prediction. - Links over time: used mainly in a dynamic network. ### Methodology of link prediction Computing score between each pair of nodes. Three types edge features #### 3.1 Distance-based features #### 3.2 Local Neighborhood Overlap ...... How GNNçš„ä¸¤ç§æŠ€æœ¯è·¯çº¿ ^8a2f39 1. ç”¨é‚»å±…æ›´æ–°â€”â€”Spatial 2. è½¬åŒ–åˆ°æ–°çš„åŸŸâ€”â€”Spectral å›¾è°±å·ç§¯ å‚è€ƒæ–‡çŒ® https://blog.csdn.net/sinat_41667427/article/details/106160643?spm=1001.2014.3001.5502 è¿™ç¯‡è®²æ‹‰æ™®æ‹‰æ–¯çŸ©é˜µé‚£å—è®²çš„ç‰¹åˆ«æ¸…æ¥š ç„¶åè¿™ç¯‡ https://blog.csdn.net/yilulvxing/article/details/110308247 çš„æœ€åé‚£ä¸€éƒ¨åˆ†ï¼ŒæŠŠå·ç§¯è¿ç®—è¿ç§»åˆ°äº†å›¾ä¸Šï¼Œè®²çš„å¾ˆæ¸…æ¥š Conv Figure-43 Spatial-Based: Aggregate Figure-44 åœ¨å›¾é‡Œå¦‚ä½•ç±»æ¯”Convæå–ä¿¡æ¯â¬†ï¸ã€‚å…¶ä¸­ç´«è‰²çº¿æŒ‡çš„Neural Networkså¿…é¡»æ˜¯order invariantï¼ˆé¡ºåºä¸å˜ï¼‰çš„ï¼Œwhich meansäº¤æ¢Neural Networksçš„è¾“å…¥èŠ‚ç‚¹çš„é¡ºåºï¼Œä¸å½±å“ç»“æœã€‚ é—®é¢˜ï¼šé‚£Aä¸å°±ç›¸å½“äºæ±‡èšäº†å¤šæ¬¡ï¼Ÿï¼ˆä¸é‡å¤ï¼Œå› ä¸ºæ¯æ¬¡éƒ½æ˜¯åˆ©ç”¨å‰ä¸€æ—¶åˆ»çš„Aï¼‰ \"image-20210316132241742\" style=\"zoom:50%;\" /&gt; æ¯ä¸ªèŠ‚ç‚¹éƒ½ç›¸å½“äºå®šä¹‰äº†ä¸€ä¸ªå›¾ã€‚ Figure-46 whatâ€™s in the box Figure-47 How to train \"image-20210316150709662\" style=\"zoom:50%;\" /&gt; åœ¨ç”Ÿæˆçš„å­å›¾ä¸Šé¢è¿›è¡Œè®­ç»ƒã€‚ Figure-49 ç„¶åå¯ä»¥åœ¨æ²¡è§è¿‡çš„å­å›¾ä¸Šè¿›è¡Œå‰å‘predictï¼ˆå¾—ç›Šäºæƒå€¼å…±äº«ï¼‰ã€‚å‰å‘predictåœ¨å¦‚å›¾çš„å­å›¾ä¸Šå°±æ˜¯ä»ä¸‹åˆ°ä¸Šçš„æ–¹å‘ã€‚ Figure-50 æƒå€¼å…±äº«ã€‚æƒå€¼çš„æ•°é‡å’Œç½‘ç»œçš„å¤§å°æ— å…³ï¼Œè€Œåªå’Œä½ çš„æ·±åº¦æœ‰å…³ ã€‚ \"image-20210316151022526\" style=\"zoom:50%;\" /&gt; åŒºåˆ†ä¸¤ç§â€œæ·±åº¦â€ åœ¨boxå†…éƒ¨æ”¾ç€çš„ç¥ç»ç½‘ç»œï¼Œæœ‰ä»–è‡ªå·±çš„â€œæ·±åº¦â€ï¼Œè¿™ä¸ªæ·±åº¦ä½ è‚¯å®šæƒ³å¤šæ·±å°±å¤šæ·±ã€‚ ä½†æ˜¯æ•´ä¸ªå­å›¾çš„â€œæ·±åº¦â€ï¼Œè¿™ä¸ªæ˜¯ä¸èƒ½å¤ªæ·±çš„ï¼ˆæ¯”å¦‚ç¤¾äº¤ç½‘ç»œï¼Œä»…ä»…å‡ å±‚æ·±åº¦å°±èƒ½è®¿é—®åˆ°å¾ˆå¤§çš„ä¸€ç‰‡å›¾äº†ï¼‰ã€‚è¿™ä¸ª æ·±åº¦è¡¨ç¤ºçš„æ˜¯â€œä½ è¦å‘å¤šå°‘é‚»å±…å€Ÿä¿¡æ¯â€ã€‚ image-20210316151613944 GAT Figure-53 GNNç»¼è¿° æ‹“æ‰‘ç‰¹å¾æå– Pytorch geometry Custom Dataset Base concepts A single graph in PyG is described by an instance of torch_geometric.data.Data, which holds the follwing attributes by default: (None of those are required.) - data.x: Node feature matrix with shape [num_nodes, num_node_features] - data.edge_index: Graph connectivity in COO format with shape [2, num_edges]. - data.edge_attr: Edge features matrix with shape [num_edges, num_edge_features]. - data.y: Target to train against (may have arbitrary shape), targets of node-level tasks of shape [num_nodes, *] or targets of graph-level tasks of shape [1, *]. - data.pos: Node position matrix with shape [num_nodes, num_dimensions]. Mini-batching Concepts of different kind of Batch stuffs. The method of mini-batch is crucial for the project which needs to train on amount of data. Instead of tranning examples one-by-one, a mini-batch groups a set of examples into a unified representation where it can effciently be processed in parallel. In CV and NLP, this generally be done by rescalling or padding each example into same size, and then group them in an additional dimension. The length of this additional dimension is equal to the numbers of examples grouped in this mini-batch, and is typically referred to as the batch_sized. Since graphs are generally contains different numbers of nodes and edges, so above approaches to do mini-batching are either not feasible or may result in a lot of unnecessary memory consumption. In Pytorch Geometry, the mini-batch was done by folloing ways: - Adjacency matrices are stacked in a diagonal fashion (creating a giant graph that holds multiple isolated subgraphs) - Node features are concatenated in the node dimension. - Target features are concatenated in the node dimension. \\[ \\mathbf{A}=\\left[\\begin{array}{ccc} \\mathbf{A}_1 &amp; &amp; \\\\ &amp; \\ddots &amp; \\\\ &amp; &amp; \\mathbf{A}_n \\end{array}\\right], \\quad \\mathbf{X}=\\left[\\begin{array}{c} \\mathbf{X}_1 \\\\ \\vdots \\\\ \\mathbf{X}_n \\end{array}\\right], \\quad \\mathbf{Y}=\\left[\\begin{array}{c} \\mathbf{Y}_1 \\\\ \\vdots \\\\ \\mathbf{Y}_n \\end{array}\\right] \\] &gt; here A is adjency matrices, X is node features, Y is target features. Figure-56 Figure-57 train with mini-batch transforms Colab notebooks","link":"/hexo_blog/2021/05/15/GNN/"},{"title":"Hexo Image Name Issues","text":"I use Obsidian as my writing IDE, and since Obsidian uses its special wiki link format, it has some issue when we publish our articles into Hexo, which use the traditional Markdown format. Here are some methods to deal with it. Embedding an image using markdown https://hexo.io/docs/asset-folders.html hexo-renderer-marked 3.1.0 introduced a new option that allows you to embed an image in markdown without using asset_img tag plugin. To enable: 1234post_asset_folder: true marked: prependRoot: true postAsset: true Once enabled, an asset image will be automatically resolved to its corresponding postâ€™s path. For example, â€œimage.jpgâ€ is located at â€œ/2020/01/02/foo/image.jpgâ€, meaning it is an asset image of â€œ/2020/01/02/foo/â€œ post, ![](image.jpg) will be rendered as &lt;img src=\"/2020/01/02/foo/image.jpg\"&gt;. Batch convert name format Sometimes we use the obsidian wiki format, but when we want to use these images in a blog, such as Hexo, the blog render engine cannot recognize the obsidian wiki format. That time we need to convert it to regular markdown image format. obsidian wiki format: ![[Image]] markdown image format: ![image-name](image.png) We can use Obsidian Link Converter Plugin to fix that issue. Auto-rename while pasting the image Use Obsidian paste image rename Plugins. Image name pattern: Modify the file name. Always add duplicate number: Start adding the prefix/suffix at the first file. Delete unused images Use the plugin Clear Unused images Need to clean manually.","link":"/hexo_blog/2023/05/15/HexoImageNameIssues/"},{"title":"ç§»åŠ¨ç¡¬ç›˜è´­ä¹°","text":"é—ªè¿ªE66çš„åŒ…è£…åèƒŒåæœ‰æ¶‚å±‚ï¼Œåˆ®å¼€åæœ‰ä¸€ä¸ªäºŒç»´ç ï¼Œæ‰«æåä¼šè¿›å…¥å®˜æ–¹çš„é˜²ä¼ªæŸ¥è¯¢ç½‘é¡µã€‚ å€¼å¾—æ³¨æ„çš„æ˜¯å¦‚æœæ˜¯é¦–æ¬¡æŸ¥è¯¢ï¼Œä»–åªä¼šè¯´æŸ¥è¯¢æˆåŠŸï¼Œæ˜¯æ­£å“ã€‚ä½†å¦‚æœæ˜¯ç¬¬äºŒæ¬¡æŸ¥è¯¢ï¼Œä»–å°±ä¼šæç¤ºè¯´è¿™å·²ç»ä¸æ˜¯ç¬¬ä¸€æ¬¡è¢«äººæŸ¥è¯¢äº†ï¼Œå¦‚æœæƒ³çŸ¥é“ç¬¬ä¸€æ¬¡æ˜¯ä»€ä¹ˆæ—¶å€™è¢«æŸ¥è¯¢çš„ï¼Œå¯ä»¥æ‰“ç”µè¯å’¨è¯¢ğŸ˜‚ã€‚","link":"/hexo_blog/2022/02/01/%E5%9B%BA%E6%80%81%E7%A1%AC%E7%9B%98%E9%80%89%E8%B4%AD/"},{"title":"Start your own Hexo blog","text":"Start the journey of blogging. Hexo is a fast, simple &amp; powerful blog framework powered by Node.js. ## å®‰è£…node.js Macå¯ä»¥åœ¨node.jå®˜ç½‘ä¸‹è½½å®‰è£…åŒ…æˆ–æºç ã€‚https://nodejs.org/zh-cn/download/ Ubuntuå¯ä»¥ç›´æ¥ç”¨å‘½ä»¤å®‰è£…ã€‚ 1apt install nodejs npm å®‰è£…hexo åœ¨hexoå®˜ç½‘é˜…è¯»æ–‡æ¡£è¿›è¡Œå®‰è£…ã€‚https://hexo.io/docs/ å®‰è£…hexo 1$ npm install -g hexo-cli å®‰è£…Hexoåï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤åœ¨ç›®æ ‡ &lt;folder&gt;ä¸­åˆå§‹åŒ–Hexoã€‚ 123$ hexo init &lt;folder&gt;$ cd &lt;folder&gt;$ npm install å®Œæˆåæ–‡ä»¶å¤¹å†…çš„ç»“æ„ä¼šå˜æˆè¿™æ ·ï¼š 12345678.â”œâ”€â”€ _config.ymlâ”œâ”€â”€ package.jsonâ”œâ”€â”€ scaffoldsâ”œâ”€â”€ source| â”œâ”€â”€ _drafts| â””â”€â”€ _postsâ””â”€â”€ themes é…ç½®Github https://hexo.io/docs/one-command-deployment å®‰è£…hexo-deployer-gitæ’ä»¶ 1$ npm install hexo-deployer-git --save åœ¨æ–‡ä»¶å¤¹å†…çš„_config.ymlæ–‡ä»¶å†…è¿›è¡Œå‚æ•°è®¾ç½® 12345deploy: type: git repo: &lt;repository url&gt; # https://bitbucket.org/JohnSmith/johnsmith.bitbucket.io branch: [branch] message: [message] ## å®‰è£…ä¸»é¢˜Icarus 1git clone https://github.com/ppoffice/hexo-theme-icarus.git themes/icarus é¦–æ¬¡é…ç½®å®Œä¼šå‡ºç°å¦‚ä¸‹é”™è¯¯ï¼ŒæŒ‰ç…§ç»¿è‰²çš„æç¤ºå®‰è£…æ‰€éœ€è¦çš„åŒ…ã€‚ **_config.ymlè®¾ç½®** å†’å·åé¢è®°å¾—åŠ ç©ºæ ¼ 1url: &lt;your url&gt; # Set your site url here. For example, if you use GitHub Page, set url as 'https://username.github.io/project' ### é…ç½®icarusä¸»é¢˜ ä¿®æ”¹ä¾§è¾¹æ å’Œæ­£æ–‡æ çš„å¤§å° https://github.com/ppoffice/hexo-theme-icarus/issues/696 https://carol-yang09.github.io/2020/11/22/hexo-icarus-themes-content-width/ vscode server æ³¨å†Œç™¾åº¦äº‘BCCäº‘æœåŠ¡å™¨ ç”¨è‡ªå¸¦çš„VNCæ‰“å¼€ ä¸‹è½½vscode server ç”¨vscode serverå®˜ç½‘çš„æ–¹æ³•ä¸èƒ½ä¸‹è½½ï¼Œå› ä¸ºäº‘æœåŠ¡å™¨ä¸èƒ½è®¿é—®ä¸€äº›ç½‘ç«™ï¼ˆ404ï¼‰ï¼Œæ‰€ä»¥éœ€è¦æ‰‹åŠ¨ä¸‹è½½åç”¨scpä¸Šä¼ ä¸Šå»ã€‚ä¸Šä¼ çš„æ—¶å€™éœ€è¦æ³¨æ„ç™¾åº¦äº‘æœåŠ¡å™¨çš„ç”¨æˆ·åé»˜è®¤å°±æ˜¯rootï¼Œè€Œä¸æ˜¯ä½ çš„å®ä¾‹å·ã€‚ 1234scp &lt;æœ¬åœ°æ–‡ä»¶åœ°å€&gt; root@&lt;å…¬ç½‘åœ°å€&gt;:~sudo dpkg -i &lt;åˆšæ‰ä¸‹è½½å¥½çš„æ–‡ä»¶&gt;sudo systemctl enable --now code-server@$USER# Now visit http://127.0.0.1:8080. Your password is in ~/.config/code-server/config.yaml å¼€å¯æœåŠ¡ã€‚ 1./code-server --port 8080 --host 0.0.0.0 --auth password --cert ~/data/full_chain.pem --cert-key ~/data/private.key 8080æ˜¯ç«¯å£,å¯ä»¥è‡ªå·±ä¿®æ”¹,æ³¨æ„ä¸è¦ä¸å…¶ä»–åº”ç”¨å†²çª. 0.0.0.0æ˜¯ä»£è¡¨å¯ä»¥è¢«æ‰€æœ‰ipè®¿é—®. ç„¶åå†æµè§ˆå™¨å†…é€šè¿‡äº‘æœåŠ¡å™¨çš„å…¬ç½‘ipå’Œç«¯å£å·å°±å¯ä»¥è®¿é—®åˆ°code serveräº†ã€‚ å¼€å¯https ä½†æ˜¯markdown previewå¿…é¡»å¼€å¯httpsæ‰å¯ä»¥æ”¯æŒé¢„è§ˆï¼Œæ‰€ä»¥è¿˜å¾—æ³¨å†Œä¸€ä¸ªåŸŸåã€‚ è´­ä¹° èº«ä»½æ¨¡æ¿åˆ›å»º éœ€è¦éªŒè¯é‚®ç®± å¡«å®Œä¸€ç³»åˆ—ä¸ªäººä¿¡æ¯å å¯åŠ¨https å¦‚æœéœ€è¦å¯ç”¨httpsæœåŠ¡çš„è¯åˆ™éœ€è¦æä¾›ä½ åŸŸåçš„sslè®¤è¯è¯ä¹¦è·¯å¾„ã€‚ httpsè®¾ç½®éœ€è¦ä½ æœ‰ä¸€ä¸ªå·²ç»è®¤è¯è¿‡çš„åŸŸåå¹¶ä¸”æœ¬åœ°ä¿å­˜äº†è¯ä¹¦å’Œkeyã€‚ åœ¨æŒ‡ä»¤åé¢æ·»åŠ ä¸¤ä¸ªå‚æ•°ã€‚ 1234cert: è®¤è¯è¯ä¹¦çš„è·¯å¾„ï¼ˆ.pemæˆ–è€….crtï¼‰cert-key: è¯ä¹¦keyçš„è·¯å¾„ï¼ˆ.keyï¼‰code-server --port 8080 --auth password --cert ~/data/full_chain.pem --cert-key ~/data/private.key æ¥ä¸‹æ¥å³å¯ç”¨httpsè®¿é—®äº†ï¼šhttps://192.168.3.7:8082 é€‰ç”¨Let's EncryptåŠ å¯† é¦–é¡µï¼Œhttps://letsencrypt.org/zh-cn/getting-started/ å®‰è£…Cerbot https://certbot.eff.org/instructions?ws=webproduct&amp;os=ubuntubionic nginxå¯åŠ¨æˆ–è€…é‡å¯å¤±è´¥ï¼ŒæŠ¥é”™nginx: [error] open() \"/usr/local/var/run/nginx.pid\" failed (2: No such file or directory) https://www.cnblogs.com/fancyLee/p/8931814.html nginx - nginx: [emerg] bind() to [::]:80 failed (98: Address already in use) https://stackoverflow.com/questions/14972792/nginx-nginx-emerg-bind-to-80-failed-98-address-already-in-use æµ‹è¯•æœ¬åœ°è¾“å…¥åå¤šä¹…ä¼šåŒæ­¥åˆ°code server","link":"/hexo_blog/2022/03/08/%E6%90%AD%E5%BB%BAhexo%E5%8D%9A%E5%AE%A2/"},{"title":"Render multi-line latex","text":"If we use default setting in hexo to render math equations, error may occour when encounter the multi-line equations. Suppose MathJax is used to render, hexo-renderer-pandoc, a markdown render engine, is recommended because it can handle mathematical formulas in markdown documents perfectly. reference: https://theme-next.js.org/docs/third-party-services/math-equations Theme Settings First, enable MathJax in the theme config file. 12345math: ... mathjax: enable: true ## Render engine If you use MathJax to render Math Equations, you can choose one of the Markdown renderers below: hexo-renderer-pandoc hexo-renderer-pandoc is recommended because it can handle mathematical formulas in markdown documents perfectly. ### Installation 1. Then you need to uninstall the original renderer hexo-renderer-marked, and install hexo-renderer-pandoc: 12$ npm un hexo-renderer-marked$ npm i hexo-renderer-pandoc 2. pandoc is required for hexo-renderer-pandoc, here's how to install pandoc.","link":"/hexo_blog/2023/05/17/RenderMulti-lineLatex/"},{"title":"Topology control of multihop wireless networks using transmit power adjustment","text":"This paper addresses the problem of controlling the topology of the network by changing the transmit powers of the nodes. Authors:: R. Ramanathan, R. Rosales-Hain ä½œè€…æœºæ„:: PublicationTitle:: undefined, IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies Date:: 2000 DateAdded:: 2023-04-18 çŠ¶æ€:: #å¾…è¯» æºç :: #æœªå¼€æº PDF Attachments document.pdf 1. Abstract Abstract A multihop wireless network is one in which a packet may have to traverse multiple consecutive wireless links in order to reach its destination. The topology of a multihop wireless network is the set of communication links between node pairs used explicitly or implicitly by a routing mechanism. \"uncontrollable\" factors to topology - node mobility - weather - interference - noise \"controllable\" factors to topology: - transmit power(this paper) - antenna direction - active movement - actively choose who to communicate Goal: Try to efficiently react to changes in the topology due to either 'uncontrollable' or 'controllable' factors. Brief idea of this paper Considerable research has been done on routing - mechanisms that efficiently react to changes in the topology due to uncontrollable factors, the area of adjusting the controllable parameters in order to create the desired topology has received little attention. This paper addresses the problem of controlling the topology of the network by changing the transmit powers of the nodes. Why do we need to control the topology? Wrong topology can: - considerably reduce the capacity, - limited spatial reuse reduces network capacity - increase the end-to-end packet delay, - high end-to-end delays - decrease the robustness to node failures. - network partitioning(more than 1 cluster) - extend battery life Networks that do not employ topology control are likely to be in one of these modes for a significant fraction of their operational time, resulting in degraded performance, or even disrupted connectivity. Related work The specific problem we consider has not been studied previously. There has been some work in the general area of topology control and network design. In [4], an algorithm based on Delaunay triangulation is given to choose logical links. The objectives and constraints used there are different from ours, and adaptive control of transmit powers is not addressed. The selection of optimal transmission range to maximize throughput is studied in [5], [6]. However, they do not describe any techniques for actually controlling the power, nor do they concern themselves with connectivity. Topology design in wired networks, both in terms of physical links and virtual links to satisfy a given traffic matrix has been fairly well studied [7], [8] and are of some relevance as a source of adaptable ideas \\({ }^1\\). In summary, no research has considered the assignment of different transmit powers to different nodes to meet a global topological property, such as a connected network and studied an implementation in the context of a prototype multihop wireless network. Contribution of this paper Formulate topology control as a constrained optimization problem of practical importance, in particular as minimizing transmit power subject to the network being connected or biconnected. Consider both static and mobile versions of the problem and give two sets of solutions, then present provably optimal algorithms for static networks and present distributed heuristics for mobile networks. 2. Problem Statement Graph definition Definition II.1: A multihop wireless network is represented as \\(M=(N, L)\\), where \\(\\mathrm{N}\\) is a set of nodes and \\(\\mathrm{L}\\) \\(: \\mathrm{N} \\rightarrow\\left(Z_0^{+}, Z_0^{+}\\right)\\)is a set of coordinates on the plane denoting the locations of the nodes. Definition II.2: A parameter vector for a given node is represented as \\(P=\\left\\{f_1, f_2, . ., f_n\\right\\}\\), where \\(f_i: \\mathrm{N} \\rightarrow \\mathrm{R}\\), is a real valued adjustable parameter. In this paper, we restrict our attention to transmit power. Thus, \\(P=\\{p\\}\\), and the transmit power of a node \\(u\\) is given by \\(p(u)\\). Following convention, we work in units of \\(\\mathrm{dB}\\) for power levels and signal strengths. Node features constrains (propagation model) Definition II.3: The propagation function is represented as \\(\\gamma: L \\times L \\rightarrow Z\\), where \\(\\mathrm{L}\\) is a set of location coordinates on the plane. \\(\\gamma\\left(l_i, l_j\\right)\\) gives the loss in \\(\\mathrm{dB}\\) due to propagation at location \\(l_j \\in L\\), when a packet is originated from location \\(l_i \\in L\\) The successful reception of a transmitted signal depends, along with the propagation function \\(\\gamma\\), on the transmit power \\(p\\), and the receiver sensitivity \\(S\\). S is the threshold signal strength needed for reception and is assumed to be an apriori known constant, same for all nodes. In particular, for successful reception, \\[ p-\\gamma\\left(l_i, l_j\\right) \\geq S \\] Here assume that \\(\\gamma\\) is a monotonically increasing function of the geographical distance \\(d\\left(l_i, l_j\\right)\\) between \\(l_i\\) and \\(l_j\\). Combine \\(S\\) and \\(\\gamma\\) into one function as follows. \\[ \\lambda(d)=\\gamma\\left(d\\left(l_i, l_j\\right)\\right)+S \\] Clearly, \\(p\\) must be at least \\(\\lambda(d)\\) for successful reception. This leads to the following defintion, of significant importance in this paper. Definition II.4: The least-power function \\(\\lambda(d)\\) gives the minimum power needed to communicate a distance of \\(d\\). Graph definition Definition II.5: Given a multihop wireless network \\(\\mathrm{M}=\\) \\((\\mathrm{N}, \\mathrm{L})\\), a transmit power function \\(p\\), and a least-power function \\(\\lambda\\), the induced graph is represented as \\(G=(V, E)\\), where \\(\\mathrm{V}\\) is a set of vertices corresponding to nodes in \\(\\mathrm{N}\\), and \\(\\mathrm{E}\\) is a set of undirected edges such that \\((u, v) \\in \\mathrm{E}\\) if and only if \\(p(u) \\geq \\lambda(d(u, v))\\), and \\(p(v) \\geq \\lambda(d(u, v))\\). Problem: Connected MinMax Power \\((C M P)\\) Objective: Minimize the maximum transmit power. Constraints: Keep connectivity and biconnectivity. Definition II.6: Connected MinMax Power \\((C M P)\\). Given an \\(\\mathrm{M}=(\\mathrm{N}, \\mathrm{L})\\), and a least-power function \\(\\lambda\\), find a per-node minimal assignment of transmit powers \\(p: \\mathrm{N} \\rightarrow Z^{+}\\), such that the induced graph of \\((M, \\lambda, p)\\) is connected, and \\(\\operatorname{MAX}_{u \\in N}(p(u))\\) is a minimum. per-node-minimal for connectivity/biconnectivity if and only if it is not possible to lower the assigned power of any single node and still keep the representative graph connected/biconnected. Thus, an assignment in which every node transmits at the solution's maximum power is still inviolate of the MinMax property but may not be per-node-minimal. Problem: Biconnectivity Augmentation Definition II.7: Problem Biconnectivity Augmentation with MinMax Power (BAMP). Given a multihop wireless net \\(M=(N, L)\\), a least-power function \\(\\lambda\\), and an initial assignment of transmit powers \\(p: \\mathrm{N} \\rightarrow Z^{+}\\), such that the induced graph of \\((\\mathrm{M}, \\lambda, \\mathrm{p})\\) is connected, find a pernode minimal set of power increases \\(\\delta(u)\\) such that the induced graph of \\((\\mathrm{M}, \\lambda, p(u)+\\delta(u))\\) is biconnected, and \\(\\operatorname{MAX}_{u \\in N}(p(u)+\\delta(u))\\) is a minimum. 3. Static Networks: Optimum Centralized Algorithms Algorithm CONNECT \"greedy\" algorithm, works by iteratively merging connected components until there is just one. Initially, each node is its own component. Node pairs are selected in non-decreasing order of their mutual distance. If the nodes are in different components, then the transmit power of each is increased to be able to just reach the other. This is done until the network is connected. CONNECT is min-max but not pernode-minimal Theorem III.1 proves CONNECT is an optimum solution to the CMP problem. But it may not be pernode-minimal. This is because a power increase may addmore than one edge to the induced graph. Such additional edges, other than the one between the selected node pairs are called side-effect edges. An example of side-effect edge is illustrated in figure 1 (a). A side-effect edge may form a loop with other edges and may allow the lowering of some power levels and the elimination of some edges added previously. An example is shown in figure \\(1(b)\\). Topology control of multihop wireless networks using transmit power adjustment-Figure-2 Deal with side-effect edges Procedure perNodeMinimalize is the simplest way to exploit side-effect edges and make the assignment per-node minimal. Main idea: Consider nodes one at a time and ramp down their powers to the maximum possible extent that does not disconnect the induced graph. Infinite possibilities: But there are theoretically infinite power levels between two power levels, and practically there may be a large number of power levels depending on the granularity of power adjustment that the radio provides. Solution: Uses a binary search over the only set of power levels that \"matter\", a set that does not depend on the granularity of the power level adjustment. This set is determined by the set of nodes that are within range of the considered node with the current power level. In theorem III.1, we show that this suffices for per-node minimality. Algorithm BICONN-AUGMENT greedy. We first identify the biconnected components in the graph induced by the power assignment from algorithm CONNECT. This is done using a standard method based on depth-first search given in [12]. Then, node pairs are selected in non-decreasing order of their mutual distance and joined only if they are in different biconnected components. This is continued until the network is biconnected. pernode-minimal: May not be per-node minimal even in the absence of side-effect edges. But, the same \"fix\" works, whatever the cause. Theorem III.1 Theorem III.1: Algorithm CONNECT is an optimum solution to the CMP problem. Correctness: - Lines 4,5 create an edge between two nodes if they are in different clusters. - Line 7 ensures that if we end then the graph is connected. - Line 3 ensures that if we end then all node pairs have been considered. - Thus, the algorithm is correct. Proof of min-max optimal: We first show that the assignment minimizes the maximum power. Following that, we will show that the assignment is per-node-minimal. Suppose to the contrary that the maximum power used is not the optimum. Consider a node \\(u\\) that is assigned the maximum power. By line 4 , this must have happened in order to connect to another node \\(v\\) in a different cluster. Further, since we consider node pairs in non-decreasing order of separation (lines 1,3), there can be no path between \\(u\\) and \\(v\\) such that all nodes along that path are separated by less than \\(d(u, v)\\). That is, \\[\\nexists \\operatorname{path}(u, v): \\forall(x, y) \\in \\operatorname{path}(u, v), d(x, y) \\leq d(u, v)\\] This is because, had there been such a path, algorithm CONNECT would have found it prior to joining \\(u\\) and \\(v\\), thereby putting \\(u\\) and \\(v\\) in the same cluster and contradicting our assumption. To see this, consider any such path \\(P\\) and consider a pair of consecutive nodes \\(x\\) and \\(y\\) in that path. Either \\(x\\) and \\(y\\) have been joined by algorithm CONNECT in line 5 or they have not. If they have, we are done. If not, it was surely ignored only because there is some other path \\(P^{\\prime}\\) already connecting them, in which case a substitution of \\(P^{\\prime}\\) in place of \\((x, y)\\) in \\(P\\) results in a path between \\(u\\) and \\(v\\). See figure 2 for illustration. By line 5 and distance monotonicity of \\(\\lambda\\), equation 3 can be rewritten as \\[ \\nexists \\operatorname{path}(u, v): \\forall x \\in \\operatorname{path}(u, v), p(x) \\leq p(u) \\] Let \\(p_{\\text {opt }}(i)\\) denote the power of node \\(i\\) under the optimum algorithm. Let OPT be the optimum solution value, that is, OPT is the maximum power in the network under the optimum algorithm. Since by supposition, OPT \\(&lt;p(u)\\), and by definition, \\[ \\forall_i\\left(p_{o p t}(i) \\leq O P T&lt;p(u)\\right) \\] we have in particular \\[ p_{o p t}(u)&lt;p(u) \\] But if this is the case, then, \\(u\\) and \\(v\\) cannot be connected directly in the optimum solution since \\(p(u)\\) is the minimum power required to connect \\(u\\) and \\(v\\) (by definition of \\(\\lambda\\) and line 5). Thus, there must be a path that connects \\(u\\) and \\(v\\) and furthermore by Eq. 5, all such nodes must have powers less than \\(p(u)\\). Formally, \\[ \\exists \\operatorname{path}(u, v): \\forall(x) \\in \\operatorname{path}(u, v), p(x) \\leq p(u) \\] This contradicts equation 4. Hence our supposition is false and algorithm CONNECT is optimum. #### Proof of pernode-minimal - Consider lines 6,7 in procedure perNodeMinimalize. Let \\(\\mathrm{T}_i=\\left(u, v_i\\right)\\) be the element for which the graph is disconnected. Thus, \\(p(u) = \\lambda\\left(\\mathrm{d}\\left(\\mathrm{T}_{i-1}\\right)\\right) = \\lambda\\left(\\mathrm{d}\\left( u, v_{i-1} \\right) \\right)\\). - Since \\(\\mathrm{T}\\) listed in non-increasing order of distance, \\[ \\nexists x: d\\left(u, v_i\\right)&lt;d(u, x)&lt;d\\left(u, v_{i-1}\\right) \\] - Now, suppose to the contrary that \\(p\\) is not minimal for node \\(u\\). Clearly, there is another power setting, say \\[\\lambda\\left(\\mathrm{d}\\left(\\mathrm{T}_i\\right)\\right) &lt; p^{\\prime}(u)&lt;p(u)\\] - Since we know that the network is not connected with \\(p(u)\\) at \\(\\lambda\\left(\\mathrm{d}\\left(\\mathrm{T}_i\\right)\\right)\\), there must be another node, say \\(x\\), such that \\(p^{\\prime}(u)\\) reaches \\(x\\). - Since \\(p(u)&gt;p^{\\prime}(u)\\), we have \\[ d\\left(u, v_{i-1}\\right)=\\lambda^{-1}(p(u))&gt;\\lambda^{-1}\\left(p^{\\prime}(u)\\right)=d(u, x) \\] - Since \\(p^{\\prime}(u)&gt;\\lambda\\left(d\\left(T_i\\right)\\right)\\), we have, taking \\(\\lambda^{-1}\\) of both sides, \\[ d(u, x)&gt;d\\left(u, v_i\\right) \\] But equations 9 and 10 contradict equation 8. Thus our supposition must be false, and hence the assignment must be per node minimal. Theorem III.2: Algorithm BICONN-AUGMENT produces an optimum solution to the BAMP problem. Proof: The correctness of BICONN-AUGMENT follows from lines 3 and 4 which force nodes to be in the same biconnected component. The proofs for optimality and pernode-minimality are similar to that for theorem III.1, and will be significantly abbreviated for lack of space. Consider a node \\(u\\) that is assigned the maximum power to form an edge with a node \\(v\\). Since we consider node pairs in non-decreasing order, following an argument analogous to that of theorem III.1, there cannot exist two disjoint paths between \\(u\\) and \\(v\\) such that all edges in these paths are at most \\(d(u, v)\\). On the other hand, if the optimum is less than \\(p(u), u\\) must have two disjoint paths to \\(v\\) in which each node pair separation is no more than \\(d(u, v)\\), forcing a contradiction. Per node minimality: is identical modulo substitution of \"connect\" for \"biconnect\" in the corresponding proof for theorem III. 1 4. MOBILE NETWORKS: DISTRUBUTED HEURISTICS In a mobile multihop wireless network, the topology is constantly changing. In this section, we present two distributed heuristics for topology control, namely Local Information No Topology (LINT) and Local Information Link-State Topology (LILT). The power minimization is done in an indirect manner by limiting the number of neighbors, and is at best a poor approximation to an optimal solution. #### LINT Description A node is configured with three parameters: the \"desired\" node degree \\(d_d\\), a high threshold on the node degree \\(d_h\\), a low threshold \\(d_l\\). Periodically, the node checks the number of active neighbors (degree) in its neighbor table (built by the routing mechanism). If the degree is greater than \\(d_h\\), the node reduces its operational power. If the degree is less than \\(d_l\\), the node increases its operational power. If neither is true, no action is taken. The magnitude of the power change is a function of desired degree \\(d_d\\) and current degree \\(d\\). In particular, the further apart \\(d\\) and \\(d_d\\) are, the more is the magnitude of the change. The power changes are done in a shuffle periodic mode, that is, the time between power changes is randomized around a mean. This is done in order to eliminate lockstep execution and interference between packets. We now derive the formula used in LINT to reduce the power. It is based on the well-known generic model for propagation [10] by which the propagation loss function varies as some \\(\\mathcal{E}\\) power of distance. The value of \\(\\mathcal{E}\\) is usually between 2 and 5 , depending on the environment. After simplifying, \\[ p_d=p_c-5 \\cdot \\mathcal{E} \\cdot \\log \\left(\\frac{d_d}{d_c}\\right) \\] A node knows the current used power \\(p_c\\) and the current degree \\(d_c\\). As mentioned before, \\(d_d\\) is a configured value. In our system, we use \\(\\mathcal{E}=4\\), but \\(\\mathcal{E}\\) can also be configured depending upon the environment. Equation (15) can thus be used to calculate the new power periodically. We note that the formula applies for both power increase and decrease to bring the degree close to \\(d_d\\). LILT Description A significant shortcoming of LINT is its incognizance of network connectivity and the consequent danger of a network partition.(Since degree-remaining doesn't guarantee the connectivity) In multihop wireless routing protocols based on the linkstate approach (such as [13], [2], [14]), some amount of global connectivity information is available locally at every node. This is available at no additional overhead to the topology control mechanism. The idea in LILT is to exploit such information for recognizing and repairing network partitions. There are two main parts to LILT - the neighbor reduction protocol (NRP) and the neighbor addition protocol (NAP). The NRP is essentially the LINT mechanism that tries to maintain the node degree around a certain configured value. The NAP is triggered whenever an event driven or periodic link-state update arrives. Its purpose is to override the high threshold bounds and increase the power if the topology change indicated by the routing update results in undesirable connectivity. The main challenge here is to coordinate such power changes with other nodes, since we do not want all nodes to react to the topology change. Initially, all nodes start with the maximum possible power. This results in a maximally connected network, enables successful propagation of updates and the initalization of a network topology database at each node. After this initialization, the NRP and NAP are activated, as follows. A node receiving a routing update first determines which of three states the updated topology is in - disconnected, connected but not biconnected, or biconnected. If it is biconnected, no action is taken. If it is disconnected, the node increases its transmit power to the maximum possible value. If it is connected, but not biconnected, the node attempts to do biconnectivity augmentation, as follows. The node first finds its distance from the closest articulation point. An articulation point is a node whose removal will partition the network. Note that if the network is connected but not biconnected, it must have at least one articulation point. Articulation points are automatically found by the biconnectivity checking procedure. The node then sets a timer for a value \\(t\\) that is randomized around an exponential function of the distance from the articulation point. If after time \\(t\\) the network is still not biconnected, the node increases its power to the maximum possible. Thus, a limited form of global coordination is achieved with zero overhead. Nodes closer to an articulation point are more likely to remove the articulation and therefore given priority using timers. The coordination is not perfect in that it is possible that the network over-reacts by having two or more nodes increase their power. However, the NRP reduces the powers to an appropriate level in time, and in any case the error is on the conservative (connectivity) side. The NRP and NAP intervals are kept sufficiently large to damp any oscillations. None have been observed in our experiments. Note that nodes increase their power immediately to the maximum value rather than step by step. This reflects the need for expediency in fixing the connectivity. The goal of biconnectivity is to ensure that even in the transient period, the network will at least be connected. Zotero links Local library Cloud library","link":"/hexo_blog/2023/05/17/Topology%20control%20of%20multihop%20wireless%20networks%20using%20transmit%20power%20adjustment/"}],"tags":[{"name":"Hexo","slug":"Hexo","link":"/hexo_blog/tags/Hexo/"},{"name":"LaTeX","slug":"LaTeX","link":"/hexo_blog/tags/LaTeX/"},{"name":"Paper notes","slug":"Paper-notes","link":"/hexo_blog/tags/Paper-notes/"}],"categories":[{"name":"Learn","slug":"Learn","link":"/hexo_blog/categories/Learn/"},{"name":"Courses","slug":"Learn/Courses","link":"/hexo_blog/categories/Learn/Courses/"},{"name":"Skills","slug":"Learn/Skills","link":"/hexo_blog/categories/Learn/Skills/"},{"name":"Software","slug":"Learn/Skills/Software","link":"/hexo_blog/categories/Learn/Skills/Software/"},{"name":"Paper notes","slug":"Learn/Paper-notes","link":"/hexo_blog/categories/Learn/Paper-notes/"}],"pages":[]}